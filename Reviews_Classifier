#import packages
import numpy as np
import pandas as pd
import re
import nltk
from nltk.stem.porter import PorterStemmer
import sklearn
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import CountVectorizer

#read in the input raw dataset
dataset = pd.read_csv('input_dataset', delimiter = '\t')
dataset.head(5)

nltk.download('stopwords')

#placeholder for cleaned reviews
clean_review = []
for i in range(len(dataset)):
    #keep letters only text
    review = re.sub('[^a-zA-Z]', ' ', dataset['Review'][i])
    #split the text to get meaningful words
    review = review.split()
    ps = PorterStemmer()
    #reduce derived words and remove stopwords
    review = [ps.stem(word) for word in review if not word in set(stopwords.words('english'))]
    review = ' '.join(review)
    clean_review.append(review)

cv = CountVectorizer(max_features = 1500)
X = cv.fit_transform(clean_review).toarray()
y = dataset.iloc[:,1].values

#split the dataset into 75% train_set and 25% test_set
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size =0.25)
#use Random Forest Classifier to fit the model and predict the reviews
clf = RandomForestClassifier(n_estimators = 501, criterion = 'entropy')
clf.fit(X_train, y_train)
y_pred = clf.predict(X_test)
y_pred

#evaluate the output using odds ratios
#true positive, true negative, false positive, false negative
from sklearn.metrics import confusion_matrix
cm = confusion_matrix(y_test, y_pred)
cm
